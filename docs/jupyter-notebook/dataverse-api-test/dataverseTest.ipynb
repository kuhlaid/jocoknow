{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "The purpose of this document is to create a Dataverse API testing notebook. See [_about_dataverseTest.md](./_about_dataverseTest.md) for information about configuring and running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _installer_dataverseTest # run the _installer_dataverseTest.py script\n",
    "%load_ext autoreload\n",
    "%autoreload all\n",
    "# we need the 'autoreload' above if we are actively making changes to the worker.py module and want to reload any changes to the module without restarting the notebook kernel\n",
    "# NOTE: if we make changes to the worker script we need to rerun this code block for the notebook to use the new edits\n",
    "\n",
    "from _worker_dataverseTest import Worker\n",
    "objWorker = Worker(\"dataverseTest\") # initialize our Worker object; we should only need to call this once for the notebook session (working with 'demo' configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dataverse Collection\n",
    "\n",
    "### Configuration\n",
    "\n",
    "Using the Dataverse starter object `DATAVERSE_COLLECTION_START` in our configuration file we will create a new collection through the API https://guides.dataverse.org/en/5.13/api/native-api.html#create-a-dataverse-collection. Luckily we do not need to follow the API documentation that instructs users to create a separate JSON file for use with the API endpoint. Since we added the JSON to our main configuration file we can simply reference the object in the `json` parameter of our request. We will place this collection under the root 'parent' collection.\n",
    "\n",
    "### Retrieving our collection info\n",
    "\n",
    "Since we already have our starter collection information defined in our main `_config_dataverseTest.json` file, there is no need to save the collection information sent back from the creation of our collection. We can always use the `DvViewCollection` method in our worker script to retrieve the collection information as long as we at least know our collection alias. \n",
    "\n",
    "### Issue\n",
    "\n",
    "Note: If you use a GET request instead of a POST request to the API endpoint, the action may appear to be successful but it will simply be returning the Dataverse collection of the main parent collection, and NOT create a new collection for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objWorker.DvCreateCollection()  # initialize a new collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objWorker.DvViewCollection()  # view information on our dataverse collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objWorker.DvDeleteCollection()  # delete our dataverse collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objWorker.DvViewCollectionContents()  # view dataverse collection contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset\n",
    "\n",
    "Using the https://guides.dataverse.org/en/5.13/_downloads/4e04c8120d51efab20e480c6427f139c/dataset-create-new-all-default-fields.json referenced in https://guides.dataverse.org/en/5.13/api/native-api.html#create-a-dataset-in-a-dataverse-collection, will be our dataset template. We simply add this JSON object to our `_config_dataverseTest.json` file under the `DATAVERSE_DATASET` constant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objWorker.DvCreateDataset()  # create a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging the Dataverse API handlers\n",
    "\n",
    "At this point we want to setup a package/module that we can load from GitHub and use in our notebook since all of our dataset notebooks will be using the same code. Have the core code in an imported module will all for ease of use by other users without the need to add the core functions into their notebook code. It simply makes things cleaner.\n",
    "\n",
    "### Package files\n",
    "\n",
    "This is an example of packaging on GitHub (which is what I want).\n",
    "https://github.com/ceddlyburge/python_world/tree/master\n",
    "\n",
    "https://packaging.python.org/en/latest/tutorials/packaging-projects/\n",
    "\n",
    "### Using imported packages\n",
    "\n",
    "https://github.com/wax911/plugin-architecture/blob/master/plugins/advanced-plugin/main.py#L14\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding files to the dataset\n",
    "\n",
    "See https://guides.dataverse.org/en/5.13/api/native-api.html#add-file-api\n",
    "\n",
    "Before we upload any files to our dataset we need to make sure we have saved the dataset persistentId to our notebook configuration. We will assume each curation notebook applies to one dataset so we only need to track on persistentId per notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue UNCDVSUP-38 (submitted on 8/17)\n",
    "\n",
    "I’m trying to use the JSON from https://guides.dataverse.org/en/5.13/_downloads/4e04c8120d51efab20e480c6427f139c/dataset-create-new-all-default-fields.json to create a new dataset in http://demo-dataverse.rdmc.unc.edu .  However I am receiving an error that makes it seem that the JSON properties are incorrectly defined. Below is the response information (with the error message appearing in https://github.com/IQSS/dataverse.harvard.edu/issues/172 ):\n",
    "\n",
    "json= {'status': 'ERROR', 'message': 'Error parsing Json: incorrect multiple   for field productionPlace'}\n",
    "headers= {'Date': 'Sat, 17 Aug 2024 16:09:07 GMT', 'Server': 'Apache/2.4.37 (Rocky Linux) OpenSSL/1.1.1k', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'PUT, GET, POST, DELETE, OPTIONS', 'Access-Control-Allow-Headers': 'Accept, Content-Type, X-Dataverse-Key, Range', 'Access-Control-Expose-Headers': 'Accept-Ranges, Content-Range, Content-Encoding', 'Content-Type': 'application/json;charset=UTF-8', 'Content-Length': '97', 'Connection': 'close'}\n",
    "response status= 400\n",
    "\n",
    "The JSON in question seems to be:\n",
    "\n",
    "{\n",
    "              \"typeName\": \"productionPlace\",\n",
    "              \"multiple\": false,\n",
    "              \"typeClass\": \"primitive\",\n",
    "              \"value\": \"ProductionPlace\"\n",
    "            },\n",
    "\n",
    "The release notes for 5.13 state: \n",
    "\n",
    "Edit the following line to your schema.xml (to indicate that productionPlace is now multiValued='true\"):\n",
    "\n",
    "So I can’t tell if the UNC Dataverse schema simply needs updating or something else is going on. If I set \"multiple\": true, in the JSON then the response is:\n",
    "\n",
    "json= {'status': 'ERROR', 'message': 'Error parsing Json: Invalid values submitted for productionPlace. It should be an array of values.'}\n",
    "\n",
    "…but I do not know how to format the JSON for multiple values.\n",
    "\n",
    "My Python method for creating the dataset is using POST so that should not be the issue.\n",
    "\n",
    "def DvCreateDataset(self):\n",
    "        print(\"start DvCreateDataset\")\n",
    "        strApiEndpoint = '%s/api/dataverses/%s/datasets' % (self.strDATAVERSE_DOMAIN, self._config[\"DATAVERSE_COLLECTION_START\"][\"alias\"])\n",
    "        print('making request: %s' % strApiEndpoint)\n",
    "        objHeaders = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"X-Dataverse-Key\": self.strDATAVERSE_API_TOKEN\n",
    "        }\n",
    "        r = requests.request(\"POST\", strApiEndpoint, json=self._config[\"DATAVERSE_DATASET\"], headers=objHeaders)\n",
    "        self.printResponseInfo(r)\n",
    "        print(\"end DvCreateDataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
